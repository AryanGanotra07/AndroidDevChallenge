
![](https://lh4.googleusercontent.com/_pS-HHzqmiogsQSJPDe_WAssiICxbVlM0qDUdHygMipMH7dXT9Mmlq8T-5mWOhLn0aQnCP7sRDHugaNFI0gl6UofnkeenQRcZWJ82D4HBaVS0W3lt-2mRCItTniud35NO5HTy-cI)

  

**Tell us what your idea is.**

----------

The idea is to help visually impaired people to listen to what is in front of them or what they can’t see. Instead of the stick they carry to guess where any object is,

  

![](https://lh3.googleusercontent.com/ueUOJjojGxOBbgJ5jsh5x4vrHIDGalACajsla7ytr0iLXynFSEK6nt8VCGMeSMAsnSBm_iJTTHlloF0A41BFeiZnV74qUINdjSyJCErHLFx8UhwoEoGJeV90j33OBxOnsFdFC0BZ)

Source- [https://electronicsforu.com/wp-contents/uploads/2019/04/3-3.jpg](https://electronicsforu.com/wp-contents/uploads/2019/04/3-3.jpg)

  

holding an android app with camera access to detect objects in front of them and describe the object through a voice. Using machine learning’s various aspects like real time object detection technique, pose estimation, text recognition, landmark recognition, I want to create an android app that would detect the surroundings of the visually impaired person and describe them through voice output - text to speech engine.

![](https://lh5.googleusercontent.com/lNPYeWLhqIiewhtqFT-QmuRef5hf_7a2AGpuTscTOP5d8iIXFFGe_vjE_XL9tQ8D4exZxKUtVCVKKYGf6WbV57vbAis22GlXuRru-uzcfGJyInHiTn0Geo2Q3L5a_6Ip4vaNB6Dh) + ![](https://lh4.googleusercontent.com/1xt7wE8MSbzZ1RPZUHxMUkBjZIc_QqrozJO3jLczNc00imSnbVUOt3fhCVxAFp6JeNAeUxKtD8k7IPz_s1OzMemMJ_GdjX8wDWftxPbR1ciMe4azkPRlz2M3nQ9ry-Y8S74RJVcM) + ![](https://lh3.googleusercontent.com/UqM2qNxOcYkQqa8JDVBY_5gzLprNd73FTsp2ZlvdNEPfa-gR1I0umzbUGpGIQn6-BqwRfv5T9p8CuZ0JK6oXHxhKKjZWH5R4J2BPiednbed6l23wwBgZtJtQmT6122_Oh6HH7WHF)

=  ![](https://lh5.googleusercontent.com/d6i8Kb-QLyCKy-Tfyps0IP8sXQLYfqVbVdgS0FKB10s8rhiw03VTUm3sBjR_U5epAQJnxn9BQjFLfXSViN45KCxPJg3LMR4i-Fzm13rPlzjrE5T3vXWF5AOhQFSwnRLlIHR0iBK4)

(Images source - Google Images)

This app will be also capable to solve their day to day problems like :

-   Looking for lost objects. Example - wallet, cap, goggles.
    
-   Will use optical character recognition techniques or text recognition to read newspaper or some form’s details.
    

  

**How machine learning will be used?**

  

This app will be completely based on the real time object detection and tracking along with text and place/landmark recognition to identify the surrounding objects. Pose estimation techniques to identify the behavior of the people in the surrounding to avoid collisions or to ask for help and also for security purposes. Machine learning models will be trained on a regular basis using the the places visited and the tasks done by the user.

  

**Thinking about how a visually impaired person will open the app to use it?**

  

Google assistant has an answer to every problem. :)

The user will be able to open the app and use it by asking google assistant to open the app and the rest the app will manage itself taking care of everything without much user interactions.

  

**Some example dialog flow**

  

**While  Looking for objects**

  

*“There is an apple in front of you”.
“A hat is on slight left”.
“A bag is on slight right”.*

  

**While walking**

  

*“There is a building in front”.
“The board on slight left reads ‘Construction work ahead’ ”.
“Two people are present in front of you”.
“Oh there we got a dog”.
“There is a bench ahead”.*

  
  

**Tell us how you plan on bringing it to life.**

----------

  

[Github Repository](https://github.com/AryanGanotra07/AndroidDevChallenge)

  

My project is at the concept phase for now. I am currently planning on what all and how to implement, also which technologies or machine learning tools will be best for this app.

  

**Features to be implemented**

-   Real time object detection and position tracker.
    
-   Text recognition.
    
-   Landmark recognition and pose estimator.
    
-   Voice outputs - Text to speech engine.
    
-   Linked with Google assistant using deep links.
    

  

**Tools to be used**

-   Detect and track objects.
    
-   Tensorflow lite’s pose estimation.
    
-   Text recognition.
    
-   Place/Landmarks recognition.
    

  

A big thanks to **Google’s ML Kit** and **TensorFlow lite** to provide all the required tools with proper optimisation.

  

**Timeline**

  

1.  **Initial phase** - **Object detector and voice output (15th February, 2020)**
    

  Set up real time object detector using Google’s ML kit and to receive output as voice or media.
    
 Managing connections to earphones, bluetooth headsets etc.
    
Make the app usable by the user without much user interactions. ( Deep linking with Google assistant)
    

  

2.  **Second phase** **- Advancement(31st March, 2020)**
    

 Implementing tensorflow lite’s pose estimation tool to depict or estimate the behaviour of the person if the detected object is a person.
    
 Implementing optical character recognition or text recognition to read the contents of a notice board or a restaurant name if the detected object is some text.
    
 Landmark recognition to describe the place to the user.
    
 Optimizing dialog flow of the voice output.
    

  

 3.  **Testing, Model training and app optimization phase.(18th April, 2020)**
    

 

	

Collecting data and managing a dataset of the user to train our
    machine learning model to improve itself.
        
 Optimizing and making app more user friendly.
        
 Implementing various tests.

    

  

**4.  Released :D (25th April, 2020)**
    

  

**Tell us about you.**

----------

I am Aryan Ganotra, a Computer Science engineering undergraduate from Delhi Technological University, New Delhi, India. I have been developing android applications and working on various Android concepts from past one year.

  

[Resume](https://drive.google.com/file/d/1j37vfq1t-oLhdXL7pOvZHhqumNPP8OHd/view?usp=sharing)

[Github](https://github.com/AryanGanotra07)

Here are my some project links

1.  Blog application and notes downloading android application for Economics Department of Jesus and Mary College, New Delhi, India.
    

[Source code](https://github.com/AryanGanotra07/JMCE)

2.  Android Blog application and stock prices viewer for Finance and Investment Cell of Shri Ram College Of Commerce, New Delhi, India
    

[Play Store](https://play.google.com/store/apps/details?id=com.aryanganotra.ficsrcc)

[Letter of recommendation](https://drive.google.com/file/d/1hab445J3ZoByDA_pkqMjapS53ee_3QRT/view?usp=sharing)

[Source Code](https://github.com/AryanGanotra07/FIC)

  

3.  Mathomon - The flappy math - A minimalistic educational game based on various arithmetic operations.
    

[Play Store](https://play.google.com/store/apps/details?id=com.codingee.mathomon&hl=en_IN)

[Source Code](https://github.com/AryanGanotra07/Mathomon)

  
  

**Conclusion**

I am aware of the various drawbacks like latency and continues detection of unnecessary objects but we can always find a solution to a problem if worked on them.

  

I have tried my best to explain the idea but if you are having a hard time getting it or have some doubts regarding it, I am ready to get back and answer any query.

  

Thanking You,

Aryan Ganotra
